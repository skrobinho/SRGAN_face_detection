import face_recognition
import os
import cv2
import pickle
import time

KNOWN_FACES_DIR = "known_faces"
TOLERANCE = 0.65
FRAME_THICKNESS = 3
FONT_THICKNESS = 2
MODEL = "hog"

video = cv2.VideoCapture("video_test.mp4")

print("loading known faces")

known_faces = []
known_names = []

if not os.path.exists(KNOWN_FACES_DIR):
  os.mkdir(KNOWN_FACES_DIR)

for name in os.listdir(KNOWN_FACES_DIR):
  for filename in os.listdir(f"{KNOWN_FACES_DIR}/{name}"):
    with open(f'{KNOWN_FACES_DIR}/{name}/{filename}', 'rb') as pickle_file:
      encoding = pickle.load(pickle_file)
    known_faces.append(encoding)
    known_names.append(int(name))

if len(known_names) > 0:
  next_id = max(known_names) + 1
else:
  next_id = 0 


print("processing unknow faces")
while True:
  ret, image = video.read()

  locations = face_recognition.face_locations(image, model=MODEL)
  encodings = face_recognition.face_encodings(image, locations)

  for face_encoding, face_location in zip(encodings, locations):
    results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)
    match = None

    if True in results:
      match = str(known_names[results.index(True)])
      print(f"Match found: {match}")
    else:
      match = str(next_id)
      next_id += 1
      known_names.append(match)
      known_faces.append(face_encoding)
      os.mkdir(f"{KNOWN_FACES_DIR}/{match}")
      pickle.dump(face_encoding, open(f"{KNOWN_FACES_DIR}/{match}/{match}-{int(time.time())}.pkl", "wb"))

    dirname = 'faces_pics'
    if not os.path.exists(f'{dirname}/{match}'):
      os.makedirs(f'{dirname}/{match}')

    roi_color = image[face_location[0]:face_location[2], face_location[3]:face_location[1]]
    cv2.imwrite(f'{dirname}/{match}/{int(time.time())}.jpg', roi_color)
    #cv2.imwrite(os.path.join(dirname, face_file_name), roi_color)

    top_left = (face_location[3], face_location[0])
    bottom_right = (face_location[1], face_location[2])
    color = [0, 255, 0]
    cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)

    top_left = (face_location[3], face_location[2])
    bottom_right = (face_location[1], face_location[2]+22)
    cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)
    cv2.putText(image, match, (face_location[3]+10, face_location[2]+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200))

  cv2.imshow("", image)
  if cv2.waitKey(1) & 0xFF == ord("q"):
    break 